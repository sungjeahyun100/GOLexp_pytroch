#!/usr/bin/env python3
"""
Game of Life CNN ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ (ê°„ì†Œí™” ë²„ì „)

ì‚¬ìš©ë²•:
    python3 train.py --dataset small_simulation --epochs 50
    python3 train.py --files ../train_data/*.txt --epochs 20
"""
import argparse
import sys
import time
import torch
import torch.nn as nn
import torch.optim as optim

from src.data_loader import DatasetLoader, load_dataset_from_files
from src.model import CNNLayer, save_model, device

def parse_args():
    parser = argparse.ArgumentParser(description='Game of Life CNN í›ˆë ¨')
    
    # ë°ì´í„° ì˜µì…˜
    data_group = parser.add_mutually_exclusive_group(required=True)
    data_group.add_argument('--dataset', type=str, 
                           help='JSON ì„¤ì •ì˜ ë°ì´í„°ì…‹ ì´ë¦„ (ì˜ˆ: small_simulation)')
    data_group.add_argument('--files', nargs='+', 
                           help='ì§ì ‘ ì§€ì •í•  ë°ì´í„° íŒŒì¼ë“¤')
    
    # í›ˆë ¨ íŒŒë¼ë¯¸í„°
    parser.add_argument('--epochs', type=int, default=50, help='ì—í¬í¬ ìˆ˜')
    parser.add_argument('--batch-size', type=int, default=32, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--lr', type=float, default=0.001, help='í•™ìŠµë¥ ')
    
    # ëª¨ë¸ íŒŒë¼ë¯¸í„°
    parser.add_argument('--activation', default='swish', help='í™œì„±í™” í•¨ìˆ˜')
    parser.add_argument('--hidden1', type=int, default=32, help='ì²« ë²ˆì§¸ ì€ë‹‰ì¸µ í¬ê¸°')
    parser.add_argument('--hidden2', type=int, default=64, help='ë‘ ë²ˆì§¸ ì€ë‹‰ì¸µ í¬ê¸°')
    
    # ê¸°íƒ€
    parser.add_argument('--output', type=str, help='ëª¨ë¸ ì €ì¥ ê²½ë¡œ')
    parser.add_argument('--quiet', action='store_true', help='ìµœì†Œ ì¶œë ¥')
    
    return parser.parse_args()

def train_model(model, dataloader, epochs, lr, quiet=False):
    """ëª¨ë¸ í›ˆë ¨"""
    criterion = nn.BCELoss()
    optimizer = optim.AdamW(model.parameters(), lr=lr)
    
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        batch_count = 0
        
        for batch_x, batch_y in dataloader:
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            
            optimizer.zero_grad()
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            batch_count += 1
        
        if not quiet and (epoch + 1) % 10 == 0:
            avg_loss = total_loss / batch_count if batch_count > 0 else 0
            print("Epoch [{}/{}], Loss: {:.4f}".format(epoch+1, epochs, avg_loss))
    
    return optimizer

def main():
    args = parse_args()
    
    if not args.quiet:
        print("ğŸš€ Game of Life CNN í›ˆë ¨ ì‹œì‘")
        if torch.cuda.is_available():
            print("GPU: {}".format(torch.cuda.get_device_name(0)))
    
    # ë°ì´í„° ë¡œë”©
    if args.dataset:
        # JSON ì„¤ì • ì‚¬ìš©
        loader = DatasetLoader("dataset_config.json")
        dataloader = loader.create_dataloader(
            args.dataset, 
            batch_size=args.batch_size,
            shuffle=True,
            num_workers=4
        )
        if dataloader is None:
            print("âŒ ë°ì´í„°ì…‹ ë¡œë”© ì‹¤íŒ¨")
            return 1
        dataset_name = args.dataset
        
    else:
        # ì§ì ‘ íŒŒì¼ ì§€ì •
        dataloader = load_dataset_from_files(
            args.files,
            batch_size=args.batch_size,
            shuffle=True,
            num_workers=4
        )
        if dataloader is None:
            print("âŒ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨")
            return 1
        dataset_name = "custom_files"
    
    # ëª¨ë¸ ìƒì„±
    model = CNNLayer(
        input_size=50,
        hidden1_size=args.hidden1,
        hidden2_size=args.hidden2,
        output_size=10,
        activate=args.activation,
        stride=1,
        use_bias=False
    ).to(device)
    
    if not args.quiet:
        total_params = sum(p.numel() for p in model.parameters())
        print("ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {:,}".format(total_params))
        print("ğŸ“Š ë°ì´í„°ì…‹ ë°°ì¹˜ ìˆ˜: {}".format(len(dataloader)))
    
    # í›ˆë ¨
    start_time = time.time()
    optimizer = train_model(model, dataloader, args.epochs, args.lr, args.quiet)
    end_time = time.time()
    
    if not args.quiet:
        print("âœ… í›ˆë ¨ ì™„ë£Œ! ì†Œìš” ì‹œê°„: {:.1f}ì´ˆ".format(end_time - start_time))
    
    # ëª¨ë¸ ì €ì¥
    if args.output:
        save_path = args.output
    else:
        save_path = "saved_models/gol_cnn_{}.pth".format(dataset_name)
    
    model_info = {
        'input_size': 50,
        'hidden1_size': args.hidden1,
        'hidden2_size': args.hidden2,
        'output_size': 10,
        'activate': args.activation,
        'epochs': args.epochs,
        'learning_rate': args.lr,
        'dataset': dataset_name
    }
    
    save_model(model, save_path, model_info, optimizer, args.epochs)
    
    if not args.quiet:
        print("ğŸ¯ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {}".format(save_path))
    
    return 0

if __name__ == "__main__":
    sys.exit(main())