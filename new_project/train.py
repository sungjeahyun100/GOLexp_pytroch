#!/usr/bin/env python3
"""
Game of Life CNN ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ (ê°„ì†Œí™” ë²„ì „)

ì‚¬ìš©ë²•:
    python3 train.py --dataset small_simulation --epochs 50
    python3 train.py --files ../train_data/*.txt --epochs 20
"""
import argparse
import os
import sys
import time
import torch
import torch.nn as nn
import torch.optim as optim

from src.data_loader import DatasetLoader, load_dataset_from_files
from src.model import CNNLayer, save_model, device
import json

def find_config_file(filename):
    """ì„¤ì • íŒŒì¼ì„ ì°¾ëŠ” ë‹¨ìˆœí™”ëœ í•¨ìˆ˜"""
    # 1. í˜„ì¬ ë””ë ‰í† ë¦¬
    if os.path.exists(filename):
        return filename
    
    # 2. ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ë””ë ‰í† ë¦¬
    script_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.join(script_dir, filename)
    if os.path.exists(config_path):
        return config_path
    
    # 3. ê¸°ë³¸ê°’ìœ¼ë¡œ í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ëª… ë°˜í™˜
    return filename

def load_model_config(model_name):
    """ëª¨ë¸ ì„¤ì •ì„ model_hyper.jsonì—ì„œ ë¡œë“œ"""
    try:
        model_config_path = find_config_file("model_hyper.json")
        with open(model_config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        if 'model_configs' not in config:
            print("âŒ model_configsê°€ model_hyper.jsonì— ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        if model_name not in config['model_configs']:
            print(f"âŒ ëª¨ë¸ '{model_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
            for name, info in config['model_configs'].items():
                print(f"  - {name}: {info['description']}")
            return None
            
        return config['model_configs'][model_name]
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def print_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¶œë ¥"""
    try:
        model_config_path = find_config_file("model_hyper.json")
        with open(model_config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            
        if 'model_configs' not in config:
            print("âŒ ëª¨ë¸ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        print("\nğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì„¤ì •:")
        for i, (name, info) in enumerate(config['model_configs'].items(), 1):
            print(f"  {i}. {name} - {info['name']}")
            print(f"     í¬ê¸°: {info['hidden1_size']}â†’{info['hidden2_size']}, í™œì„±í™”: {info['activation']}")
            print(f"     ì¶”ì²œ: epochs={info['recommended_epochs']}, lr={info['recommended_lr']}, batch={info['recommended_batch_size']}")
            print(f"     ì„¤ëª…: {info['description']}")
        print()
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")

def load_experiment_config(experiment_name):
    """ì‹¤í—˜ ì„¤ì •ì„ dataset_config.jsonì—ì„œ ë¡œë“œ"""
    try:
        config_path = find_config_file("dataset_config.json")
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        if 'custom_experiments' not in config:
            print("âŒ custom_experimentsê°€ ì„¤ì • íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        if experiment_name not in config['custom_experiments']:
            print(f"âŒ ì‹¤í—˜ '{experiment_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤í—˜:")
            for name, info in config['custom_experiments'].items():
                print(f"  - {name}: {info['description']}")
            return None
            
        return config['custom_experiments'][experiment_name]
    except Exception as e:
        print(f"âŒ ì‹¤í—˜ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def print_available_experiments():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤í—˜ ëª©ë¡ ì¶œë ¥"""
    try:
        config_path = find_config_file("dataset_config.json")
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            
        if 'custom_experiments' not in config:
            print("âŒ ì‹¤í—˜ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        print("\nğŸ§ª ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤í—˜ ì„¤ì •:")
        for i, (name, info) in enumerate(config['custom_experiments'].items(), 1):
            print(f"  {i}. {name} - {info['name']}")
            print(f"     ë°ì´í„°ì…‹: {info['dataset']}, ëª¨ë¸: {info['model']}")
            print(f"     í›ˆë ¨: epochs={info['training_params']['epochs']}, lr={info['training_params']['learning_rate']}")
            print(f"     ì„¤ëª…: {info['description']}")
            print(f"     ë…¸íŠ¸: {info['notes']}")
        print()
    except Exception as e:
        print(f"âŒ ì‹¤í—˜ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")

def parse_args():
    parser = argparse.ArgumentParser(description='Game of Life CNN í›ˆë ¨')
    
    # ë°ì´í„° ì˜µì…˜ (--list-modelsì¼ ë•ŒëŠ” optional)
    data_group = parser.add_mutually_exclusive_group(required=False)
    data_group.add_argument('--dataset', type=str, 
                           help='JSON ì„¤ì •ì˜ ë°ì´í„°ì…‹ ì´ë¦„ (ì˜ˆ: small_simulation)')
    data_group.add_argument('--files', nargs='+', 
                           help='ì§ì ‘ ì§€ì •í•  ë°ì´í„° íŒŒì¼ë“¤')
    
    # í›ˆë ¨ íŒŒë¼ë¯¸í„°
    parser.add_argument('--epochs', type=int, default=50, help='ì—í¬í¬ ìˆ˜')
    parser.add_argument('--batch-size', type=int, default=32, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--lr', type=float, default=0.001, help='í•™ìŠµë¥ ')
    
    # ì‹¤í—˜ ì„¤ì • ì˜µì…˜
    exp_group = parser.add_mutually_exclusive_group()
    exp_group.add_argument('--experiment', type=str,
                          help='JSON ì„¤ì •ì˜ ì‹¤í—˜ ì´ë¦„ (ì˜ˆ: my_experiment_1)')
    exp_group.add_argument('--model-config', type=str, 
                           help='JSON ì„¤ì •ì˜ ëª¨ë¸ ì´ë¦„ (ì˜ˆ: standard_cnn)')
    exp_group.add_argument('--custom-model', action='store_true',
                           help='ìˆ˜ë™ ëª¨ë¸ íŒŒë¼ë¯¸í„° ì‚¬ìš©')
    
    # ìˆ˜ë™ ëª¨ë¸ íŒŒë¼ë¯¸í„° (--custom-modelê³¼ í•¨ê»˜ ì‚¬ìš©)
    parser.add_argument('--activation', default='swish', help='í™œì„±í™” í•¨ìˆ˜')
    parser.add_argument('--hidden1', type=int, default=32, help='ì²« ë²ˆì§¸ ì€ë‹‰ì¸µ í¬ê¸°')
    parser.add_argument('--hidden2', type=int, default=64, help='ë‘ ë²ˆì§¸ ì€ë‹‰ì¸µ í¬ê¸°')
    parser.add_argument('--use-bias', action='store_true', help='bias ì‚¬ìš© ì—¬ë¶€')
    parser.add_argument('--stride', type=int, default=1, help='stride ê°’')
    
    # ê¸°íƒ€
    parser.add_argument('--output', type=str, help='ëª¨ë¸ ì €ì¥ ê²½ë¡œ')
    parser.add_argument('--quiet', action='store_true', help='ìµœì†Œ ì¶œë ¥')
    parser.add_argument('--list-models', action='store_true', help='ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ í‘œì‹œ')
    parser.add_argument('--list-experiments', action='store_true', help='ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤í—˜ ëª©ë¡ í‘œì‹œ')
    
    return parser.parse_args()

def train_model(model, dataloader, epochs, lr, quiet=False):
    """ëª¨ë¸ í›ˆë ¨"""
    criterion = nn.BCELoss()
    optimizer = optim.AdamW(model.parameters(), lr=lr)
    
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        batch_count = 0
        
        for batch_x, batch_y in dataloader:
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            
            optimizer.zero_grad()
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            batch_count += 1
        
        if not quiet and (epoch + 1) % 10 == 0:
            avg_loss = total_loss / batch_count if batch_count > 0 else 0
            print("Epoch [{}/{}], Loss: {:.4f}".format(epoch+1, epochs, avg_loss))
    
    return optimizer

def main():
    args = parse_args()
    
    # ëª©ë¡ í‘œì‹œ í›„ ì¢…ë£Œ
    if args.list_models:
        print_available_models()
        return 0
    
    if args.list_experiments:
        print_available_experiments()
        return 0
    
    # ì‹¤í—˜ ì„¤ì • ì²˜ë¦¬
    if args.experiment:
        experiment_config = load_experiment_config(args.experiment)
        if experiment_config is None:
            print_available_experiments()
            return 1
        
        # ì‹¤í—˜ ì„¤ì •ì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        args.dataset = experiment_config['dataset']
        args.model_config = experiment_config['model']
        
        # í›ˆë ¨ íŒŒë¼ë¯¸í„° ì ìš© (ëª…ë ¹í–‰ ì¸ìê°€ ê¸°ë³¸ê°’ì¸ ê²½ìš°ë§Œ)
        if args.epochs == 50:  # ê¸°ë³¸ê°’
            args.epochs = experiment_config['training_params']['epochs']
        if args.lr == 0.001:  # ê¸°ë³¸ê°’
            args.lr = experiment_config['training_params']['learning_rate']
        if args.batch_size == 32:  # ê¸°ë³¸ê°’
            args.batch_size = experiment_config['training_params']['batch_size']
        
        if not args.quiet:
            print(f"ğŸ§ª ì‹¤í—˜ ì„¤ì •: {experiment_config['name']}")
            print(f"   ì„¤ëª…: {experiment_config['description']}")
            print(f"   ë°ì´í„°ì…‹: {experiment_config['dataset']}")
            print(f"   ëª¨ë¸: {experiment_config['model']}")
            print(f"   ë…¸íŠ¸: {experiment_config['notes']}")
    
    # ì¼ë°˜ í›ˆë ¨ ì‹œì—ëŠ” ë°ì´í„°ì…‹ì´ í•„ìˆ˜
    if not args.dataset and not args.files:
        print("âŒ ì˜¤ë¥˜: í›ˆë ¨ì„ ìœ„í•´ì„œëŠ” --dataset, --files, ë˜ëŠ” --experimentê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        print("ğŸ’¡ ì‚¬ìš©ë²•:")
        print("   python3 train.py --experiment my_experiment_1")
        print("   python3 train.py --dataset custom_experiment_1 --model-config small_cnn")
        print("   python3 train.py --list-experiments  # ì‹¤í—˜ ëª©ë¡ í™•ì¸")
        print("   python3 train.py --list-models  # ëª¨ë¸ ëª©ë¡ í™•ì¸")
        return 1
    
    if not args.quiet:
        print("ğŸš€ Game of Life CNN í›ˆë ¨ ì‹œì‘")
        if torch.cuda.is_available():
            print("GPU: {}".format(torch.cuda.get_device_name(0)))
    
    # ë°ì´í„° ë¡œë”©
    if args.dataset:
        # JSON ì„¤ì • ì‚¬ìš© - config íŒŒì¼ ê²½ë¡œ ìë™ íƒì§€
        config_path = find_config_file("dataset_config.json")
        loader = DatasetLoader(config_path)
        dataloader = loader.create_dataloader(
            args.dataset, 
            batch_size=args.batch_size,
            shuffle=True,
            num_workers=4
        )
        if dataloader is None:
            print("âŒ ë°ì´í„°ì…‹ ë¡œë”© ì‹¤íŒ¨")
            return 1
        dataset_name = args.dataset
        
    else:
        # ì§ì ‘ íŒŒì¼ ì§€ì •
        dataloader = load_dataset_from_files(
            args.files,
            batch_size=args.batch_size,
            shuffle=True,
            num_workers=4
        )
        if dataloader is None:
            print("âŒ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨")
            return 1
        dataset_name = "custom_files"
    
    # ëª¨ë¸ ì„¤ì • ê²°ì •
    if args.model_config:
        # JSON ì„¤ì • ì‚¬ìš©
        config_path = find_config_file("dataset_config.json")
        model_config = load_model_config(args.model_config)
        if model_config is None:
            print_available_models()
            return 1
            
        # ì¶”ì²œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš© (ëª…ë ¹í–‰ ì¸ìê°€ ê¸°ë³¸ê°’ì¸ ê²½ìš°)
        if args.epochs == 50:  # ê¸°ë³¸ê°’
            args.epochs = model_config['recommended_epochs']
        if args.lr == 0.001:  # ê¸°ë³¸ê°’
            args.lr = model_config['recommended_lr']
        if args.batch_size == 32:  # ê¸°ë³¸ê°’
            args.batch_size = model_config['recommended_batch_size']
            # ì´ë¯¸ ìƒì„±ëœ dataloaderê°€ ìˆë‹¤ë©´ ì¬ìƒì„± í•„ìš”
            if args.dataset:
                dataloader = loader.create_dataloader(
                    args.dataset, 
                    batch_size=args.batch_size,
                    shuffle=True,
                    num_workers=4
                )
        
        model_name = args.model_config
        if not args.quiet:
            print(f"ğŸ¯ ëª¨ë¸ ì„¤ì •: {model_config['name']}")
            print(f"   {model_config['description']}")
            print(f"   êµ¬ì¡°: {model_config['hidden1_size']}â†’{model_config['hidden2_size']}")
            print(f"   í™œì„±í™”: {model_config['activation']}, bias: {model_config['use_bias']}")
    else:
        # ìˆ˜ë™ ì„¤ì • ì‚¬ìš© (ê¸°ë³¸ê°’ ë˜ëŠ” ëª…ë ¹í–‰ ì¸ì)
        model_config = {
            'input_size': 50,
            'hidden1_size': args.hidden1,
            'hidden2_size': args.hidden2,
            'output_size': 10,
            'activation': args.activation,
            'stride': args.stride,
            'use_bias': args.use_bias
        }
        model_name = "custom"
        if not args.quiet:
            print("ğŸ”§ ì»¤ìŠ¤í…€ ëª¨ë¸ ì„¤ì • ì‚¬ìš©")

    # ëª¨ë¸ ìƒì„±
    model = CNNLayer(
        input_size=model_config['input_size'],
        hidden1_size=model_config['hidden1_size'],
        hidden2_size=model_config['hidden2_size'],
        output_size=model_config['output_size'],
        activate=model_config['activation'],
        stride=model_config['stride'],
        use_bias=model_config['use_bias']
    ).to(device)
    
    if not args.quiet:
        total_params = sum(p.numel() for p in model.parameters())
        print("ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {:,}".format(total_params))
        if dataloader is not None:
            print("ğŸ“Š ë°ì´í„°ì…‹ ë°°ì¹˜ ìˆ˜: {}".format(len(dataloader)))
    
    # í›ˆë ¨
    start_time = time.time()
    optimizer = train_model(model, dataloader, args.epochs, args.lr, args.quiet)
    end_time = time.time()
    
    if not args.quiet:
        print("âœ… í›ˆë ¨ ì™„ë£Œ! ì†Œìš” ì‹œê°„: {:.1f}ì´ˆ".format(end_time - start_time))
    
    # ëª¨ë¸ ì €ì¥
    if args.output:
        save_path = args.output
    else:
        save_path = "saved_models/gol_cnn_{}_{}.pth".format(dataset_name, model_name)
    
    # ëª¨ë¸ ì •ë³´ì— ì‹¤ì œ ì‚¬ìš©ëœ ì„¤ì • ì €ì¥
    model_info = model_config.copy()
    model_info.update({
        'epochs': args.epochs,
        'learning_rate': args.lr,
        'dataset': dataset_name,
        'model_config_name': model_name,
        'batch_size': args.batch_size
    })
    
    save_model(model, save_path, model_info, optimizer, args.epochs)
    
    if not args.quiet:
        print("ğŸ¯ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {}".format(save_path))
    
    return 0

if __name__ == "__main__":
    sys.exit(main())